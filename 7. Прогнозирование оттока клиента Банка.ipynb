{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Использование-техники-upsampling\" data-toc-modified-id=\"Использование-техники-upsampling-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Использование техники upsampling</a></span></li><li><span><a href=\"#Использование-параметра-class_weight='balanced'\" data-toc-modified-id=\"Использование-параметра-class_weight='balanced'-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Использование параметра class_weight='balanced'</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Вывод</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Подготовка-данных\" data-toc-modified-id=\"1.-Подготовка-данных-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><b>1. Подготовка данных</b></a></span></li><li><span><a href=\"#2.-Исследование-задачи\" data-toc-modified-id=\"2.-Исследование-задачи-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span><b>2. Исследование задачи</b></a></span></li><li><span><a href=\"#3.-Борьба-с-дисбалансом\" data-toc-modified-id=\"3.-Борьба-с-дисбалансом-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span><b>3. Борьба с дисбалансом</b></a></span></li><li><span><a href=\"#4.-Тестирование-модели\" data-toc-modified-id=\"4.-Тестирование-модели-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span><b>4. Тестирование модели</b></a></span></li></ul></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.9/site-packages (0.0)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.9/site-packages (from imblearn) (0.10.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.9.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.1.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Импортирую нужные библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>15643966</td>\n",
       "      <td>Goforth</td>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>15737452</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>15788218</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>15661507</td>\n",
       "      <td>Muldrow</td>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>15568982</td>\n",
       "      <td>Hao</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602   Hargrave          619    France  Female   42   \n",
       "1           2    15647311       Hill          608     Spain  Female   41   \n",
       "2           3    15619304       Onio          502    France  Female   42   \n",
       "3           4    15701354       Boni          699    France  Female   39   \n",
       "4           5    15737888   Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012        Chu          645     Spain    Male   44   \n",
       "6           7    15592531   Bartlett          822    France    Male   50   \n",
       "7           8    15656148     Obinna          376   Germany  Female   29   \n",
       "8           9    15792365         He          501    France    Male   44   \n",
       "9          10    15592389         H?          684    France    Male   27   \n",
       "10         11    15767821     Bearce          528    France    Male   31   \n",
       "11         12    15737173    Andrews          497     Spain    Male   24   \n",
       "12         13    15632264        Kay          476    France  Female   34   \n",
       "13         14    15691483       Chin          549    France  Female   25   \n",
       "14         15    15600882      Scott          635     Spain  Female   35   \n",
       "15         16    15643966    Goforth          616   Germany    Male   45   \n",
       "16         17    15737452      Romeo          653   Germany    Male   58   \n",
       "17         18    15788218  Henderson          549     Spain  Female   24   \n",
       "18         19    15661507    Muldrow          587     Spain    Male   45   \n",
       "19         20    15568982        Hao          726    France  Female   24   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0      2.0       0.00              1          1               1   \n",
       "1      1.0   83807.86              1          0               1   \n",
       "2      8.0  159660.80              3          1               0   \n",
       "3      1.0       0.00              2          0               0   \n",
       "4      2.0  125510.82              1          1               1   \n",
       "5      8.0  113755.78              2          1               0   \n",
       "6      7.0       0.00              2          1               1   \n",
       "7      4.0  115046.74              4          1               0   \n",
       "8      4.0  142051.07              2          0               1   \n",
       "9      2.0  134603.88              1          1               1   \n",
       "10     6.0  102016.72              2          0               0   \n",
       "11     3.0       0.00              2          1               0   \n",
       "12    10.0       0.00              2          1               0   \n",
       "13     5.0       0.00              2          0               0   \n",
       "14     7.0       0.00              2          1               1   \n",
       "15     3.0  143129.41              2          0               1   \n",
       "16     1.0  132602.88              1          1               0   \n",
       "17     9.0       0.00              2          1               1   \n",
       "18     6.0       0.00              1          0               0   \n",
       "19     6.0       0.00              2          1               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  \n",
       "15         64327.26       0  \n",
       "16          5097.67       1  \n",
       "17         14406.41       0  \n",
       "18        158684.81       0  \n",
       "19         54724.03       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрю данные\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "data.info();\n",
    "\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных отсутствуют пропуски, кроме Tenure, что позволяет сразу перейти к работе с ними. \n",
    "\n",
    "Exited - категориальный признак, поэтому нужно решить задачу классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираю столбцы с номером строки, id клиента и фамилией, потому что они не пригодятся в обучении моделей\n",
    "\n",
    "target = data['Exited']\n",
    "features = data.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "\n",
    "# Использую технику прямого кодирования (One-Hot Encoding). Чтобы не попасть в дамми-ловушку, применяю аргумент drop_first функции pd.get_dummies()..\n",
    "\n",
    "features = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Выделяю валидационную выборку\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Выделяю тестовую выборку из оставшихся тренировочных данных\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартизирую признаки\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: (5454, 11)\n",
      "\n",
      "Размер валидационной выборки: (1819, 11)\n",
      "\n",
      "Размер тестовой выборки: (1818, 11)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "5          645   44     8.0  113755.78              2          1   \n",
       "6          822   50     7.0       0.00              2          1   \n",
       "7          376   29     4.0  115046.74              4          1   \n",
       "8          501   44     4.0  142051.07              2          0   \n",
       "9          684   27     2.0  134603.88              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "0               1        101348.88                  0                0   \n",
       "1               1        112542.58                  0                1   \n",
       "2               0        113931.57                  0                0   \n",
       "3               0         93826.63                  0                0   \n",
       "4               1         79084.10                  0                1   \n",
       "5               0        149756.71                  0                1   \n",
       "6               1         10062.80                  0                0   \n",
       "7               0        119346.88                  1                0   \n",
       "8               1         74940.50                  0                0   \n",
       "9               1         71725.73                  0                0   \n",
       "\n",
       "   Gender_Male  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            1  \n",
       "6            1  \n",
       "7            0  \n",
       "8            1  \n",
       "9            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Размер тренировочной выборки:',features_train.shape)\n",
    "print()\n",
    "print('Размер валидационной выборки:',features_valid.shape)\n",
    "print()\n",
    "print('Размер тестовой выборки:',features_test.shape)\n",
    "print()\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7237\n",
       "1    1854\n",
       "Name: CreditScore, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Exited')['CreditScore'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Итоги подготовки данных</b>\n",
    "\n",
    "В данных отсутствуют пропуски, кроме Tenure, что позволяет сразу перейти к работе с ними.\n",
    "\n",
    "Exited - категориальный признак, поэтому нужно было решить задачу классификации.\n",
    "\n",
    "Для корректного обучения модели стандартизировал следующие признаки:\n",
    "\n",
    "   - Кредитный рейтинг('CreditScore')\n",
    "   - Возраст ('Age')\n",
    "   - Возраст ('Tenure')\n",
    "   - Баланс на счёте ('Balance')\n",
    "   - Предполагаемая зарплата ('EstimatedSalary')\n",
    "\n",
    "Для корректного обучения модели следующие признаки не учитывались:\n",
    "\n",
    " - индекс строки в данных ('RowNumber')\n",
    " - уникальный идентификатор клиента ('CustomerId')\n",
    " - фамилия ('Surname')\n",
    " \n",
    "Для лучшего обучения моделей была использована техника прямого кодирования (One-Hot Encoding).\n",
    "\n",
    "Данные были разделены на выборки:\n",
    " - Тренировочную (60%)\n",
    " - Валидационную (20%)\n",
    " - Тестовую (20%)\n",
    "\n",
    "В данных наблюдается значательный перевес в пользу отрицательного класса целевого признака. Положительного класса в четыре раза меньше, чем отрицательного.\n",
    "\n",
    " - Объём отрицательного класса: 7237\n",
    " - Объём положительного класса: 1854\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели LogisticRegression: 0.32653061224489793\n",
      "\n",
      "Показатель AUC-ROC модели LogisticRegression на валидационной выборке: 0.7881824128586113\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"логистическая регрессия\" и смотрю на её показатели без учёта дисбаланса\n",
    "\n",
    "model_1 = LogisticRegression(random_state=12345, max_iter=1000, solver='lbfgs') \n",
    "model_1.fit(features_train, target_train)\n",
    "predicted_valid_model_1 = model_1.predict(features_valid)\n",
    "\n",
    "print('F1-мера модели LogisticRegression:', f1_score(target_valid, predicted_valid_model_1))\n",
    "\n",
    "probabilities_valid = model_1.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_1 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели LogisticRegression на валидационной выборке:', auc_roc_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72551724, 0.27448276],\n",
       "       [0.2899729 , 0.7100271 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=predicted_valid_model_1, y_true=target_valid, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели DecisionTreeClassifier: 0.5942684766214177\n",
      "Оптимальная глубина дерева: 9\n",
      "\n",
      "Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке: 0.8037790860667227\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"дерево решений\" и смотрю на её показатели без учёта дисбаланса\n",
    "\n",
    "best_depth = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100):\n",
    "    model_2 = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model_2.fit(features_train, target_train)\n",
    "    predicted_valid_model_2 = model_2.predict(features_valid)\n",
    "    result = f1_score(target_valid, predicted_valid_model_2)\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print('Лучшая F1-мера модели DecisionTreeClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "\n",
    "model_2 = DecisionTreeClassifier(random_state=12345, max_depth=best_depth) \n",
    "model_2.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке:', auc_roc_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93310345, 0.06689655],\n",
       "       [0.46612466, 0.53387534]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = DecisionTreeClassifier(random_state=12345, max_depth=best_depth) \n",
    "model_2.fit(features_train, target_train)\n",
    "predicted_valid_model_2 = model_2.predict(features_valid)\n",
    "\n",
    "confusion_matrix(y_pred=predicted_valid_model_2, y_true=target_valid, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели RandomForestClassifier: 0.5621805792163544\n",
      "Оптимальная глубина дерева: 26\n",
      "Оптимальное количество деревьев: 71\n",
      "\n",
      "Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке: 0.8534875245304175\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"случайный лес\" и смотрю на её показатели без учёта дисбаланса\n",
    "\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100, 5):\n",
    "    for est in range(1, 100, 5):\n",
    "        model_3_1 = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth ) \n",
    "        model_3_1.fit(features_train, target_train)\n",
    "        predicted_valid_model_3_1 = model_3_1.predict(features_valid)\n",
    "        result = f1_score(target_valid, predicted_valid_model_3_1)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print('Лучшая F1-мера модели RandomForestClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "print('Оптимальное количество деревьев:', best_est)\n",
    "\n",
    "model_3_2 = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth ) \n",
    "model_3_2.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model_3_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_3_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке:', auc_roc_model_3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97310345, 0.02689655],\n",
       "       [0.59349593, 0.40650407]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_2 = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth ) \n",
    "model_3_2.fit(features_train, target_train)\n",
    "predicted_valid_model_3_2 = model_3_2.predict(features_valid)\n",
    "\n",
    "confusion_matrix(y_pred=predicted_valid_model_3_2, y_true=target_valid, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dummy = DummyClassifier(random_state=12345)\n",
    "model_dummy.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid_model_dummy = model_dummy.predict(features_valid)\n",
    "\n",
    "confusion_matrix(y_pred=predicted_valid_model_dummy, y_true=target_valid, normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты настройки моделей классификации и подбора оптимальных параметров <b>без учёта дисбаланса</b>:\n",
    "\n",
    "<b>Показатели F1-меры без учёта дисбаланса:</b>\n",
    " \n",
    "  - Моделью с самой высокой F1-мерой является дерево решений (DecisionTreeClassifier). Его F1-мера составляет <b>0.5942684766214177</b> при глубине дерева 9. \n",
    " \n",
    "\n",
    "  - На втором месте по значению F1-меры - случайный лес (RandomForestClassifier). Его F1-мера <b>0.5621805792163544</b>. При числе деревьев (n_estimators) 71 и глубине (max_depth) 26, эти парметры являются оптимальными.\n",
    " \n",
    "\n",
    "  - На третьем месте логистическая регрессия (LogisticRegression) с F1-мерой <b>0.32653061224489793</b>.\n",
    "  \n",
    "<b>Показатели AUC-ROC без учёта дисбаланса:</b>\n",
    "\n",
    " - Самое высокое значение AUC-ROC на валидационной выборке у случайного леса (RandomForestClassifier) - <b>0.8534875245304175</b>\n",
    " \n",
    " \n",
    " - На втором месте по значению AUC-ROC - дерево решений (DecisionTreeClassifier). Его показатель AUC-ROC на валидационной выборке <b>0.8037790860667227</b> \n",
    " \n",
    " \n",
    " - На третьем месте логистическая регрессия (LogisticRegression) с показатель AUC-ROC на валидационной выборке <b>0.7881824128586113</b>.\n",
    " \n",
    "При проверке моделей на адекватность с помощбю «дамми-классифайера» виден перекос в пользу положительного класса. Ложно положительных ответов значительно больше, чем отрицательных, у случайного леса и дерева решений. Самой адекватной моделью оказалась логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование техники upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробую использовать технику upsampling для преодоления дисбаланса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаю новую тренировочную выборку\n",
    "\n",
    "oversample = SMOTE(random_state=12345)\n",
    "\n",
    "features_upsampled, target_upsampled = oversample.fit_resample(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели LogisticRegression: 0.5070422535211268\n",
      "\n",
      "Показатель AUC-ROC модели LogisticRegression на валидационной выборке: 0.7823829548640314\n"
     ]
    }
   ],
   "source": [
    "# Обучаю модель \"логистическая регрессия\" на новой тренировочной выборке и смотрю её показатели F1-меры и AUC-ROC\n",
    "\n",
    "model_1 = LogisticRegression(random_state=12345, max_iter=1000, solver='lbfgs') \n",
    "model_1.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid_model_1 = model_1.predict(features_valid)\n",
    "\n",
    "print('F1-мера модели LogisticRegression:', f1_score(target_valid, predicted_valid_model_1))\n",
    "\n",
    "probabilities_valid = model_1.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_1 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели LogisticRegression на валидационной выборке:', auc_roc_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели DecisionTreeClassifier: 0.5445665445665445\n",
      "Оптимальная глубина дерева: 8\n",
      "\n",
      "Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке: 0.8004158489860762\n"
     ]
    }
   ],
   "source": [
    "# Обучаю модель \"дерево решений\" на новой тренировочной выборке и смотрю её показатели F1-меры и AUC-ROC\n",
    "\n",
    "best_depth = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100):\n",
    "    model_2 = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model_2.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid_model_2 = model_2.predict(features_valid)\n",
    "    result = f1_score(target_valid, predicted_valid_model_2)\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print('Лучшая F1-мера модели DecisionTreeClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "\n",
    "model_2 = DecisionTreeClassifier(random_state=12345, max_depth=best_depth) \n",
    "model_2.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "probabilities_valid = model_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке:', auc_roc_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели RandomForestClassifier: 0.6277712952158694\n",
      "Оптимальная глубина дерева: 6\n",
      "Оптимальное количество деревьев: 61\n",
      "\n",
      "Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке: 0.8602392299785065\n"
     ]
    }
   ],
   "source": [
    "# Обучаю модель \"случайный лес\" на новой тренировочной выборке и смотрю её показатели F1-меры и AUC-ROC\n",
    "\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100, 5):\n",
    "    for est in range(1, 100, 5):\n",
    "        model_3_1 = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth ) \n",
    "        model_3_1.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid_model_3_1 = model_3_1.predict(features_valid)\n",
    "        result = f1_score(target_valid, predicted_valid_model_3_1)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print('Лучшая F1-мера модели RandomForestClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "print('Оптимальное количество деревьев:', best_est)\n",
    "\n",
    "model_3_2 = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth ) \n",
    "model_3_2.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "probabilities_valid = model_3_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_3_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке:', auc_roc_model_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование параметра class_weight='balanced'\n",
    "\n",
    "Для того, чтобы сбалансировать классы, я добавил в параметры моделей class_weight='balanced'. Это помогло значительно повысить показатели  F1-меры. Этот метод оказался эффективнее техники upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели LogisticRegression: 0.5092322643343051\n",
      "\n",
      "Показатель AUC-ROC модели LogisticRegression на валидационной выборке: 0.7880796187272219\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"логистическая регрессия\" и смотрю на её показатели с учётом дисбаланса\n",
    "\n",
    "model_1 = LogisticRegression(random_state=12345, max_iter=1000, solver='lbfgs', class_weight='balanced') \n",
    "model_1.fit(features_train, target_train)\n",
    "predicted_valid_model_1 = model_1.predict(features_valid)\n",
    "\n",
    "print('F1-мера модели LogisticRegression:', f1_score(target_valid, predicted_valid_model_1))\n",
    "\n",
    "probabilities_valid = model_1.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_1 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели LogisticRegression на валидационной выборке:', auc_roc_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели DecisionTreeClassifier: 0.5741728922091781\n",
      "Оптимальная глубина дерева: 6\n",
      "\n",
      "Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке: 0.8272096065788244\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"дерево решений\" и смотрю на её показатели с учётом дисбаланса\n",
    "\n",
    "best_depth = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100):\n",
    "    model_2 = DecisionTreeClassifier(random_state=12345, class_weight='balanced', max_depth=depth) \n",
    "    model_2.fit(features_train, target_train)\n",
    "    predicted_valid_model_2 = model_2.predict(features_valid)\n",
    "    result = f1_score(target_valid, predicted_valid_model_2)\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print('Лучшая F1-мера модели DecisionTreeClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "\n",
    "model_2 = DecisionTreeClassifier(random_state=12345, class_weight='balanced', max_depth=6) \n",
    "model_2.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели DecisionTreeClassifier на валидационной выборке:', auc_roc_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера модели RandomForestClassifier: 0.619718309859155\n",
      "Оптимальная глубина дерева: 9\n",
      "Оптимальное количество деревьев: 31\n",
      "\n",
      "Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке: 0.8550359779459864\n"
     ]
    }
   ],
   "source": [
    "# Применяю модель \"случайный лес\" и смотрю на её показатели с учётом дисбаланса\n",
    "\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "best_result = 0\n",
    "for depth in range(1, 100, 2):\n",
    "    for est in range(1, 100, 2):\n",
    "        model_3_1 = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced') \n",
    "        model_3_1.fit(features_train, target_train)\n",
    "        predicted_valid_model_3_1 = model_3_1.predict(features_valid)\n",
    "        result = f1_score(target_valid, predicted_valid_model_3_1)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print('Лучшая F1-мера модели RandomForestClassifier:', best_result)\n",
    "print('Оптимальная глубина дерева:', best_depth)\n",
    "print('Оптимальное количество деревьев:', best_est)\n",
    "\n",
    "model_3_2 = RandomForestClassifier(random_state=12345, n_estimators=best_est, max_depth=best_depth, class_weight='balanced') \n",
    "model_3_2.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model_3_2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_model_3_2 = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('Показатель AUC-ROC модели RandomForestClassifier на валидационной выборке:', auc_roc_model_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты настройки моделей классификации и подбора оптимальных параметров <b>с учётом дисбаланса</b> с использованием параметра class_weight='balanced':\n",
    "\n",
    "<b>Показатели F1-меры:</b>\n",
    " \n",
    "  - Моделью с самой высокой F1-мерой является случайный лес (RandomForestClassifier). Его F1-мера составляет <b>0.619718309859155</b>. При числе деревьев (n_estimators) 31 и глубине (max_depth) 9, эти парметры являются оптимальными. Однако благодаря технике upsampling удалось добиться еще более высоких показателей F1-меры - <b>0.6277712952158694</b> (при количестве деревьев 61 и глубине деревьев 6)\n",
    " \n",
    "\n",
    "  - На втором месте по значению F1-меры - дерево решений (DecisionTreeClassifier). Его F1-мера <b>0.5741728922091781</b> при глубине дерева 6.\n",
    " \n",
    "\n",
    "  - На третьем месте логистическая регрессия (LogisticRegression) с F1-мерой <b>0.5092322643343051</b>.\n",
    "  \n",
    "<b>Показатели AUC-ROC:</b>\n",
    "\n",
    " - Самое высокое значение AUC-ROC на валидационной выборке у случайного леса (RandomForestClassifier) - <b>0.8550359779459864</b>\n",
    " \n",
    " \n",
    " - На втором месте по значению AUC-ROC - дерево решений (DecisionTreeClassifier). Его показатель AUC-ROC на валидационной выборке <b>0.8272096065788244</b> \n",
    " \n",
    " \n",
    " - На третьем месте логистическая регрессия (LogisticRegression) с показатель AUC-ROC на валидационной выборке <b>0.7880796187272219</b>.\n",
    " \n",
    "С коррекцией моделей с учётом дисбаланса у случайного леса (RandomForestClassifier) значительно повысились показатели F1-меры и AUC-ROC. По показателям F1-меры случайный лес, таким образом, оказался лучшей моделью. При этом на тестовой выборке более высокие показатели F1-меры были достигнуты благодаря использованию параметра <b>class_weight='balanced'</b>, а не техники <b>upsampling</b>.\n",
    "\n",
    "Показатель F1-меры с учётом дисбаланса у логистической регрессии (LogisticRegression) увеличился больше всего, при этом показатель AUC-ROC практически не изменился.\n",
    "\n",
    "Показатель F1-меры с учётом дисбаланса у дерева решений (DecisionTreeClassifier) наоборот уменьшился, но при этом увеличилось значение AUC-ROC.\n",
    "\n",
    "Использование параметра <b>class_weight='balanced'</b> для моделей дерева решений (DecisionTreeClassifier) и логистической регрессии (LogisticRegression) даёт более эффективный результат для увеличения метрики F1-меры, техника upsampling в данном случае менее эффективна.\n",
    "\n",
    "Техника <b>upsampling</b> оказалась более эффективна, чем использование параметра <b>class_weight='balanced'</b>, для модели случайного леса (RandomForestClassifier) на валидационной выборке, но не на тестовой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели RandomForestClassifier на тестовой выборке: 0.5981554677206852\n",
      "Показатель AUC-ROC модели RandomForestClassifier на тестовой выборке: 0.8496740881241627\n"
     ]
    }
   ],
   "source": [
    "model_3_2 = RandomForestClassifier(random_state=12345, n_estimators=31, class_weight='balanced', max_depth=9 ) \n",
    "model_3_2.fit(features_train, target_train)\n",
    "predicted_test_model_3_2 = model_3_2.predict(features_test)\n",
    "result = f1_score(target_test, predicted_test_model_3_2)\n",
    "print('F1-мера модели RandomForestClassifier на тестовой выборке:', result)\n",
    "\n",
    "probabilities_test = model_3_2.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc_model_3_2 = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "print('Показатель AUC-ROC модели RandomForestClassifier на тестовой выборке:', auc_roc_model_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты проверки лучшей модели, случайного леса (RandomForestClassifier), на тестовой выборке:\n",
    "\n",
    " - <b>F1-мера</b> модели RandomForestClassifier на тестовой выборке: <b>0.5981554677206852</b>\n",
    " \n",
    " \n",
    " - Показатель <b>AUC-ROC</b> модели RandomForestClassifier на тестовой выборке: <b>0.8496740881241627</b>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В работе с данными и обучении модели были сделаны следующие шаги:\n",
    "\n",
    "    1. Подготовка данных\n",
    "    2. Исследование задачи\n",
    "    3. Борьба с дисбалансом\n",
    "    4. Тестирование модели\n",
    "\n",
    "### <b>1. Подготовка данных</b>\n",
    "\n",
    "В данных отсутствуют пропуски, кроме Tenure, что позволяет сразу перейти к работе с ними.\n",
    "\n",
    "Exited - категориальный признак, поэтому нужно было решить задачу классификации.\n",
    "\n",
    "Для корректного обучения модели стандартизировал следующие признаки:\n",
    "\n",
    "   - Кредитный рейтинг('CreditScore')\n",
    "   - Возраст ('Age')\n",
    "   - Возраст ('Tenure')\n",
    "   - Баланс на счёте ('Balance')\n",
    "   - Предполагаемая зарплата ('EstimatedSalary')\n",
    "\n",
    "Для корректного обучения модели следующие признаки не учитывались:\n",
    "\n",
    " - индекс строки в данных ('RowNumber')\n",
    " - уникальный идентификатор клиента ('CustomerId')\n",
    " - фамилия ('Surname')\n",
    " \n",
    "Для лучшего обучения моделей была использована техника прямого кодирования (One-Hot Encoding).\n",
    "\n",
    "Данные были разделены на выборки:\n",
    " - Тренировочную (60%)\n",
    " - Валидационную (20%)\n",
    " - Тестовую (20%)\n",
    "\n",
    "В данных наблюдается значательный перевес в пользу отрицательного класса целевого признака. Положительного класса в четыре раза меньше, чем отрицательного.\n",
    "\n",
    " - Объём отрицательного класса: 7237\n",
    " - Объём положительного класса: 1854\n",
    "\n",
    "### <b>2. Исследование задачи</b>\n",
    "\n",
    "Результаты настройки моделей классификации и подбора оптимальных параметров <b>без учёта дисбаланса</b>:\n",
    "\n",
    "<b>Показатели F1-меры без учёта дисбаланса:</b>\n",
    " \n",
    "  - Моделью с самой высокой F1-мерой является дерево решений (DecisionTreeClassifier). Его F1-мера составляет <b>0.5942684766214177</b> при глубине дерева 9. \n",
    " \n",
    "\n",
    "  - На втором месте по значению F1-меры - случайный лес (RandomForestClassifier). Его F1-мера <b>0.5621805792163544</b>. При числе деревьев (n_estimators) 71 и глубине (max_depth) 26, эти парметры являются оптимальными.\n",
    " \n",
    "\n",
    "  - На третьем месте логистическая регрессия (LogisticRegression) с F1-мерой <b>0.32653061224489793</b>.\n",
    "  \n",
    "<b>Показатели AUC-ROC без учёта дисбаланса:</b>\n",
    "\n",
    " - Самое высокое значение AUC-ROC на валидационной выборке у случайного леса (RandomForestClassifier) - <b>0.8534875245304175</b>\n",
    " \n",
    " \n",
    " - На втором месте по значению AUC-ROC - дерево решений (DecisionTreeClassifier). Его показатель AUC-ROC на валидационной выборке <b>0.8037790860667227</b> \n",
    " \n",
    " \n",
    " - На третьем месте логистическая регрессия (LogisticRegression) с показатель AUC-ROC на валидационной выборке <b>0.7881824128586113</b>.\n",
    " \n",
    "Результаты настройки моделей классификации и подбора оптимальных параметров <b>без учёта дисбаланса</b>:\n",
    "\n",
    "<b>Показатели F1-меры без учёта дисбаланса:</b>\n",
    " \n",
    "  - Моделью с самой высокой F1-мерой является дерево решений (DecisionTreeClassifier). Его F1-мера составляет <b>0.5942684766214177</b> при глубине дерева 9. \n",
    " \n",
    "\n",
    "  - На втором месте по значению F1-меры - случайный лес (RandomForestClassifier). Его F1-мера <b>0.5621805792163544</b>. При числе деревьев (n_estimators) 71 и глубине (max_depth) 26, эти парметры являются оптимальными.\n",
    " \n",
    "\n",
    "  - На третьем месте логистическая регрессия (LogisticRegression) с F1-мерой <b>0.32653061224489793</b>.\n",
    "  \n",
    "<b>Показатели AUC-ROC без учёта дисбаланса:</b>\n",
    "\n",
    " - Самое высокое значение AUC-ROC на валидационной выборке у случайного леса (RandomForestClassifier) - <b>0.8534875245304175</b>\n",
    " \n",
    " \n",
    " - На втором месте по значению AUC-ROC - дерево решений (DecisionTreeClassifier). Его показатель AUC-ROC на валидационной выборке <b>0.8037790860667227</b> \n",
    " \n",
    " \n",
    " - На третьем месте логистическая регрессия (LogisticRegression) с показатель AUC-ROC на валидационной выборке <b>0.7881824128586113</b>.\n",
    " \n",
    "При проверке моделей на адекватность с помощбю «дамми-классифайера» виден перекос в пользу положительного класса. Ложно положительных ответов значительно больше, чем отрицательных, у случайного леса и дерева решений. Самой адекватной моделью оказалась логистическая регрессия.\n",
    " \n",
    "### <b>3. Борьба с дисбалансом</b>\n",
    "\n",
    "Результаты настройки моделей классификации и подбора оптимальных параметров <b>с учётом дисбаланса</b> с использованием параметра class_weight='balanced':\n",
    "\n",
    "<b>Показатели F1-меры:</b>\n",
    " \n",
    "  - Моделью с самой высокой F1-мерой является случайный лес (RandomForestClassifier). Его F1-мера составляет <b>0.619718309859155</b>. При числе деревьев (n_estimators) 31 и глубине (max_depth) 9, эти парметры являются оптимальными. Однако благодаря технике upsampling удалось добиться еще более высоких показателей F1-меры - <b>0.6277712952158694</b> (при количестве деревьев 61 и глубине деревьев 6)\n",
    " \n",
    "\n",
    "  - На втором месте по значению F1-меры - дерево решений (DecisionTreeClassifier). Его F1-мера <b>0.5741728922091781</b> при глубине дерева 6.\n",
    " \n",
    "\n",
    "  - На третьем месте логистическая регрессия (LogisticRegression) с F1-мерой <b>0.5092322643343051</b>.\n",
    "  \n",
    "<b>Показатели AUC-ROC:</b>\n",
    "\n",
    " - Самое высокое значение AUC-ROC на валидационной выборке у случайного леса (RandomForestClassifier) - <b>0.8550359779459864</b>\n",
    " \n",
    " \n",
    " - На втором месте по значению AUC-ROC - дерево решений (DecisionTreeClassifier). Его показатель AUC-ROC на валидационной выборке <b>0.8272096065788244</b> \n",
    " \n",
    " \n",
    " - На третьем месте логистическая регрессия (LogisticRegression) с показатель AUC-ROC на валидационной выборке <b>0.7880796187272219</b>.\n",
    " \n",
    "С коррекцией моделей с учётом дисбаланса у случайного леса (RandomForestClassifier) значительно повысились показатели F1-меры и AUC-ROC. По показателям F1-меры случайный лес, таким образом, оказался лучшей моделью. При этом на тестовой выборке более высокие показатели F1-меры были достигнуты благодаря использованию параметра <b>class_weight='balanced'</b>, а не техники <b>upsampling</b>.\n",
    "\n",
    "Показатель F1-меры с учётом дисбаланса у логистической регрессии (LogisticRegression) увеличился больше всего, при этом показатель AUC-ROC практически не изменился.\n",
    "\n",
    "Показатель F1-меры с учётом дисбаланса у дерева решений (DecisionTreeClassifier) наоборот уменьшился, но при этом увеличилось значение AUC-ROC.\n",
    "\n",
    "Использование параметра <b>class_weight='balanced'</b> для моделей дерева решений (DecisionTreeClassifier) и логистической регрессии (LogisticRegression) даёт более эффективный результат для увеличения метрики F1-меры, техника upsampling в данном случае менее эффективна.\n",
    "\n",
    "Техника <b>upsampling</b> оказалась более эффективна, чем использование параметра <b>class_weight='balanced'</b>, для модели случайного леса (RandomForestClassifier) на валидационной выборке, но не на тестовой.\n",
    "\n",
    "### <b>4. Тестирование модели</b>\n",
    "\n",
    "Результаты проверки лучшей модели, случайного леса (RandomForestClassifier), на тестовой выборке:\n",
    "\n",
    " - <b>F1-мера</b> модели RandomForestClassifier на тестовой выборке: <b>0.5981554677206852</b>\n",
    " \n",
    " \n",
    " - Показатель <b>AUC-ROC</b> модели RandomForestClassifier на тестовой выборке: <b>0.8496740881241627</b>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1028,
    "start_time": "2023-01-01T08:39:36.032Z"
   },
   {
    "duration": 87,
    "start_time": "2023-01-01T08:40:41.718Z"
   },
   {
    "duration": 64,
    "start_time": "2023-01-01T08:42:09.027Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-01T09:00:40.284Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-01T09:01:05.502Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-01T09:19:28.163Z"
   },
   {
    "duration": 777,
    "start_time": "2023-01-01T09:24:56.452Z"
   },
   {
    "duration": 2,
    "start_time": "2023-01-01T09:25:16.140Z"
   },
   {
    "duration": 60,
    "start_time": "2023-01-01T09:25:16.799Z"
   },
   {
    "duration": 1003,
    "start_time": "2023-01-01T09:25:30.753Z"
   },
   {
    "duration": 66,
    "start_time": "2023-01-01T09:25:31.757Z"
   },
   {
    "duration": 869,
    "start_time": "2023-01-01T09:25:31.824Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T09:25:32.694Z"
   },
   {
    "duration": 783,
    "start_time": "2023-01-01T09:26:04.471Z"
   },
   {
    "duration": 671,
    "start_time": "2023-01-01T09:26:48.709Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-01T09:28:00.082Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-01T09:28:02.476Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-01T10:07:30.116Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T10:21:06.094Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-01T10:21:13.297Z"
   },
   {
    "duration": 58,
    "start_time": "2023-01-01T10:21:13.825Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-01T10:21:14.764Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T10:21:15.144Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-01T10:21:18.687Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-01T10:21:35.355Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T10:28:24.346Z"
   },
   {
    "duration": 2707,
    "start_time": "2023-01-01T10:28:47.291Z"
   },
   {
    "duration": 70,
    "start_time": "2023-01-01T10:28:50.000Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-01T10:28:50.071Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T10:28:50.089Z"
   },
   {
    "duration": 106,
    "start_time": "2023-01-01T10:28:50.098Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-01T10:32:20.520Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-01T10:35:37.314Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T10:35:38.866Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-01T10:35:41.334Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-01T10:39:04.378Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-01T10:39:05.946Z"
   },
   {
    "duration": 103,
    "start_time": "2023-01-01T10:39:08.320Z"
   },
   {
    "duration": 137,
    "start_time": "2023-01-01T10:39:33.080Z"
   },
   {
    "duration": 2252,
    "start_time": "2023-01-01T10:45:33.162Z"
   },
   {
    "duration": 12321,
    "start_time": "2023-01-01T10:51:40.414Z"
   },
   {
    "duration": 29814,
    "start_time": "2023-01-01T10:53:40.067Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-01T11:02:25.993Z"
   },
   {
    "duration": 152,
    "start_time": "2023-01-01T11:02:26.380Z"
   },
   {
    "duration": 112,
    "start_time": "2023-01-01T11:02:27.226Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-01T11:02:27.611Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-01T11:03:46.627Z"
   },
   {
    "duration": 99,
    "start_time": "2023-01-01T11:03:47.020Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-01T11:03:47.725Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-01T11:04:10.753Z"
   },
   {
    "duration": 55,
    "start_time": "2023-01-01T11:04:11.193Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-01T11:04:12.699Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-01T11:04:13.386Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-01T11:04:13.816Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-01T11:04:14.561Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-01T11:04:33.346Z"
   },
   {
    "duration": 265,
    "start_time": "2023-01-01T11:04:36.252Z"
   },
   {
    "duration": 2294,
    "start_time": "2023-01-01T11:04:38.413Z"
   },
   {
    "duration": 11098,
    "start_time": "2023-01-01T11:04:43.296Z"
   },
   {
    "duration": 24304,
    "start_time": "2023-01-01T11:05:14.779Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-01T11:08:24.832Z"
   },
   {
    "duration": 269,
    "start_time": "2023-01-01T11:08:26.154Z"
   },
   {
    "duration": 2256,
    "start_time": "2023-01-01T11:08:27.967Z"
   },
   {
    "duration": 11051,
    "start_time": "2023-01-01T11:08:31.634Z"
   },
   {
    "duration": 24373,
    "start_time": "2023-01-01T11:08:42.686Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-01T11:12:15.687Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-01T11:12:44.180Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-01T11:15:20.499Z"
   },
   {
    "duration": 104,
    "start_time": "2023-01-01T11:15:23.614Z"
   },
   {
    "duration": 414,
    "start_time": "2023-01-01T11:15:24.736Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-01T11:15:46.786Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-01T11:15:59.287Z"
   },
   {
    "duration": 94,
    "start_time": "2023-01-01T11:16:01.025Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-01T11:16:24.776Z"
   },
   {
    "duration": 131,
    "start_time": "2023-01-01T11:16:26.189Z"
   },
   {
    "duration": 2274,
    "start_time": "2023-01-01T11:16:27.498Z"
   },
   {
    "duration": 11100,
    "start_time": "2023-01-01T11:16:29.774Z"
   },
   {
    "duration": 24313,
    "start_time": "2023-01-01T11:16:40.876Z"
   },
   {
    "duration": 28,
    "start_time": "2023-01-01T11:17:05.190Z"
   },
   {
    "duration": 156,
    "start_time": "2023-01-01T11:29:03.162Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-01T11:30:28.912Z"
   },
   {
    "duration": 116,
    "start_time": "2023-01-01T11:30:35.600Z"
   },
   {
    "duration": 2273,
    "start_time": "2023-01-01T11:30:37.856Z"
   },
   {
    "duration": 11020,
    "start_time": "2023-01-01T11:30:40.130Z"
   },
   {
    "duration": 24108,
    "start_time": "2023-01-01T11:30:51.152Z"
   },
   {
    "duration": 20235,
    "start_time": "2023-01-01T11:31:45.827Z"
   },
   {
    "duration": 382,
    "start_time": "2023-01-01T11:33:16.456Z"
   },
   {
    "duration": 386,
    "start_time": "2023-01-01T11:33:41.418Z"
   },
   {
    "duration": 375,
    "start_time": "2023-01-01T11:34:19.344Z"
   },
   {
    "duration": 384,
    "start_time": "2023-01-01T11:39:07.527Z"
   },
   {
    "duration": 385,
    "start_time": "2023-01-01T11:40:21.676Z"
   },
   {
    "duration": 402,
    "start_time": "2023-01-01T11:40:34.959Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-01T11:40:59.852Z"
   },
   {
    "duration": 412,
    "start_time": "2023-01-01T11:41:06.876Z"
   },
   {
    "duration": 202,
    "start_time": "2023-01-01T11:51:48.422Z"
   },
   {
    "duration": 2430,
    "start_time": "2023-01-01T11:52:58.303Z"
   },
   {
    "duration": 20623,
    "start_time": "2023-01-01T11:54:07.295Z"
   },
   {
    "duration": 2,
    "start_time": "2023-01-01T12:03:25.285Z"
   },
   {
    "duration": 92,
    "start_time": "2023-01-01T12:05:04.639Z"
   },
   {
    "duration": 270,
    "start_time": "2023-01-01T12:05:09.846Z"
   },
   {
    "duration": 2288,
    "start_time": "2023-01-01T12:06:18.816Z"
   },
   {
    "duration": 11372,
    "start_time": "2023-01-01T12:07:31.284Z"
   },
   {
    "duration": 24830,
    "start_time": "2023-01-01T12:08:52.580Z"
   },
   {
    "duration": 44,
    "start_time": "2023-01-01T20:40:38.576Z"
   },
   {
    "duration": 1044,
    "start_time": "2023-01-01T20:40:52.625Z"
   },
   {
    "duration": 105,
    "start_time": "2023-01-01T20:40:53.672Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-01T20:40:53.778Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T20:40:53.796Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-01T20:40:53.805Z"
   },
   {
    "duration": 99,
    "start_time": "2023-01-01T20:40:53.821Z"
   },
   {
    "duration": 2429,
    "start_time": "2023-01-01T20:40:53.921Z"
   },
   {
    "duration": 11235,
    "start_time": "2023-01-01T20:40:56.351Z"
   },
   {
    "duration": 26109,
    "start_time": "2023-01-01T20:41:07.588Z"
   },
   {
    "duration": 106,
    "start_time": "2023-01-01T20:41:33.700Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T20:41:33.812Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T20:41:33.813Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T20:41:33.815Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T20:41:33.816Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-01T20:41:33.818Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-01T20:42:13.469Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-01T20:42:28.120Z"
   },
   {
    "duration": 222,
    "start_time": "2023-01-01T20:43:07.193Z"
   },
   {
    "duration": 306,
    "start_time": "2023-01-01T20:43:23.011Z"
   },
   {
    "duration": 162,
    "start_time": "2023-01-01T20:43:28.352Z"
   },
   {
    "duration": 224,
    "start_time": "2023-01-01T20:43:45.089Z"
   },
   {
    "duration": 4119,
    "start_time": "2023-01-01T20:44:55.060Z"
   },
   {
    "duration": 3941,
    "start_time": "2023-01-01T20:46:51.667Z"
   },
   {
    "duration": 69739,
    "start_time": "2023-01-01T20:48:06.220Z"
   },
   {
    "duration": 804,
    "start_time": "2023-01-01T21:28:40.817Z"
   },
   {
    "duration": 415,
    "start_time": "2023-01-01T21:28:41.623Z"
   },
   {
    "duration": 20863,
    "start_time": "2023-01-01T21:29:09.116Z"
   },
   {
    "duration": 1085,
    "start_time": "2023-01-01T21:31:09.291Z"
   },
   {
    "duration": 72,
    "start_time": "2023-01-01T21:31:10.378Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-01T21:31:10.452Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-01T21:31:10.473Z"
   },
   {
    "duration": 37,
    "start_time": "2023-01-01T21:31:10.483Z"
   },
   {
    "duration": 291,
    "start_time": "2023-01-01T21:31:10.522Z"
   },
   {
    "duration": 2418,
    "start_time": "2023-01-01T21:31:10.818Z"
   },
   {
    "duration": 11451,
    "start_time": "2023-01-01T21:31:13.237Z"
   },
   {
    "duration": 25901,
    "start_time": "2023-01-01T21:31:24.689Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-01T21:31:50.593Z"
   },
   {
    "duration": 395,
    "start_time": "2023-01-01T21:31:50.617Z"
   },
   {
    "duration": 4138,
    "start_time": "2023-01-01T21:31:51.015Z"
   },
   {
    "duration": 72403,
    "start_time": "2023-01-01T21:31:55.155Z"
   },
   {
    "duration": 163,
    "start_time": "2023-01-01T21:33:07.560Z"
   },
   {
    "duration": 2421,
    "start_time": "2023-01-01T21:33:07.814Z"
   },
   {
    "duration": 1017,
    "start_time": "2023-01-01T21:46:36.262Z"
   },
   {
    "duration": 68,
    "start_time": "2023-01-01T21:46:37.280Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-01T21:46:37.350Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-01T21:46:37.367Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-01T21:46:37.376Z"
   },
   {
    "duration": 223,
    "start_time": "2023-01-01T21:46:37.393Z"
   },
   {
    "duration": 2466,
    "start_time": "2023-01-01T21:46:37.618Z"
   },
   {
    "duration": 11398,
    "start_time": "2023-01-01T21:46:40.086Z"
   },
   {
    "duration": 26010,
    "start_time": "2023-01-01T21:46:51.485Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-01T21:47:17.497Z"
   },
   {
    "duration": 302,
    "start_time": "2023-01-01T21:47:17.516Z"
   },
   {
    "duration": 4075,
    "start_time": "2023-01-01T21:47:17.820Z"
   },
   {
    "duration": 71668,
    "start_time": "2023-01-01T21:47:21.897Z"
   },
   {
    "duration": 247,
    "start_time": "2023-01-01T21:48:33.566Z"
   },
   {
    "duration": 2565,
    "start_time": "2023-01-01T21:48:33.815Z"
   },
   {
    "duration": 11790,
    "start_time": "2023-01-01T21:48:36.383Z"
   },
   {
    "duration": 21394,
    "start_time": "2023-01-01T21:48:48.175Z"
   },
   {
    "duration": 819,
    "start_time": "2023-01-01T21:49:09.571Z"
   },
   {
    "duration": 413,
    "start_time": "2023-01-01T21:49:10.392Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-02T18:55:21.952Z"
   },
   {
    "duration": 1002,
    "start_time": "2023-01-02T18:55:33.476Z"
   },
   {
    "duration": 111,
    "start_time": "2023-01-02T18:55:34.479Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T18:55:34.591Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T18:55:34.601Z"
   },
   {
    "duration": 98,
    "start_time": "2023-01-02T18:55:34.619Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.721Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.722Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.723Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.725Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.725Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.727Z"
   },
   {
    "duration": 1,
    "start_time": "2023-01-02T18:55:34.727Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.729Z"
   },
   {
    "duration": 1,
    "start_time": "2023-01-02T18:55:34.729Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.731Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.732Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.733Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T18:55:34.734Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T18:56:02.988Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T18:56:57.204Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T18:57:37.326Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T18:58:13.525Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T18:58:23.278Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T18:58:34.402Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-02T18:59:20.686Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-02T19:04:16.537Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T19:04:29.800Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T19:08:15.500Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T19:08:44.058Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T19:09:46.489Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T19:10:02.472Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T19:10:23.624Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T19:10:43.103Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T19:11:00.475Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T19:11:05.702Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T19:11:17.232Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T19:12:39.018Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T19:53:40.193Z"
   },
   {
    "duration": 1016,
    "start_time": "2023-01-02T19:57:21.562Z"
   },
   {
    "duration": 65,
    "start_time": "2023-01-02T19:57:22.579Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T19:57:22.645Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-02T19:57:22.654Z"
   },
   {
    "duration": 32,
    "start_time": "2023-01-02T19:57:22.673Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T19:57:22.707Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-02T19:57:22.724Z"
   },
   {
    "duration": 84,
    "start_time": "2023-01-02T19:57:22.740Z"
   },
   {
    "duration": 2214,
    "start_time": "2023-01-02T19:57:22.830Z"
   },
   {
    "duration": 13846,
    "start_time": "2023-01-02T19:57:25.046Z"
   },
   {
    "duration": 33829,
    "start_time": "2023-01-02T19:57:38.893Z"
   },
   {
    "duration": 109,
    "start_time": "2023-01-02T19:58:12.723Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.834Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.836Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.837Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.839Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.841Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.842Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.844Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T19:58:12.846Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-02T19:58:35.873Z"
   },
   {
    "duration": 1002,
    "start_time": "2023-01-02T20:01:20.788Z"
   },
   {
    "duration": 65,
    "start_time": "2023-01-02T20:01:21.792Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T20:01:21.861Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-02T20:01:21.871Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T20:01:21.890Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T20:01:21.921Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T20:01:21.935Z"
   },
   {
    "duration": 87,
    "start_time": "2023-01-02T20:01:21.944Z"
   },
   {
    "duration": 2211,
    "start_time": "2023-01-02T20:01:22.124Z"
   },
   {
    "duration": 13905,
    "start_time": "2023-01-02T20:01:24.337Z"
   },
   {
    "duration": 33828,
    "start_time": "2023-01-02T20:01:38.243Z"
   },
   {
    "duration": 106,
    "start_time": "2023-01-02T20:02:12.073Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.180Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.182Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.183Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.184Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.185Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.186Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.187Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.187Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T20:02:12.189Z"
   },
   {
    "duration": 6112,
    "start_time": "2023-01-02T20:02:31.465Z"
   },
   {
    "duration": 1976,
    "start_time": "2023-01-02T20:02:52.191Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T20:04:17.810Z"
   },
   {
    "duration": 2854,
    "start_time": "2023-01-02T20:04:35.680Z"
   },
   {
    "duration": 70,
    "start_time": "2023-01-02T20:04:38.537Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T20:04:38.610Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-02T20:04:38.620Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T20:04:38.639Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T20:04:38.653Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T20:04:38.668Z"
   },
   {
    "duration": 149,
    "start_time": "2023-01-02T20:04:38.674Z"
   },
   {
    "duration": 2164,
    "start_time": "2023-01-02T20:04:38.824Z"
   },
   {
    "duration": 14661,
    "start_time": "2023-01-02T20:04:40.990Z"
   },
   {
    "duration": 35679,
    "start_time": "2023-01-02T20:04:55.653Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T20:05:31.333Z"
   },
   {
    "duration": 173,
    "start_time": "2023-01-02T20:05:31.348Z"
   },
   {
    "duration": 3777,
    "start_time": "2023-01-02T20:05:31.524Z"
   },
   {
    "duration": 67993,
    "start_time": "2023-01-02T20:05:35.303Z"
   },
   {
    "duration": 124,
    "start_time": "2023-01-02T20:06:43.298Z"
   },
   {
    "duration": 2234,
    "start_time": "2023-01-02T20:06:43.424Z"
   },
   {
    "duration": 14136,
    "start_time": "2023-01-02T20:06:45.660Z"
   },
   {
    "duration": 24814,
    "start_time": "2023-01-02T20:06:59.798Z"
   },
   {
    "duration": 480,
    "start_time": "2023-01-02T20:07:24.614Z"
   },
   {
    "duration": 7612,
    "start_time": "2023-01-02T21:32:02.472Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.086Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.088Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.089Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.091Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.095Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.097Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.098Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.099Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.100Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.102Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.103Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.105Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.106Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.107Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.109Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.110Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.112Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.114Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-02T21:32:10.114Z"
   },
   {
    "duration": 2010,
    "start_time": "2023-01-02T21:32:44.708Z"
   },
   {
    "duration": 3045,
    "start_time": "2023-01-02T21:32:54.016Z"
   },
   {
    "duration": 106,
    "start_time": "2023-01-02T21:32:57.063Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T21:32:57.171Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T21:32:57.182Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-02T21:32:57.200Z"
   },
   {
    "duration": 36,
    "start_time": "2023-01-02T21:32:57.231Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T21:32:57.269Z"
   },
   {
    "duration": 35,
    "start_time": "2023-01-02T21:32:57.275Z"
   },
   {
    "duration": 2259,
    "start_time": "2023-01-02T21:32:57.311Z"
   },
   {
    "duration": 15583,
    "start_time": "2023-01-02T21:32:59.573Z"
   },
   {
    "duration": 37325,
    "start_time": "2023-01-02T21:33:15.158Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-02T21:33:52.484Z"
   },
   {
    "duration": 296,
    "start_time": "2023-01-02T21:33:52.509Z"
   },
   {
    "duration": 3825,
    "start_time": "2023-01-02T21:33:52.807Z"
   },
   {
    "duration": 71980,
    "start_time": "2023-01-02T21:33:56.633Z"
   },
   {
    "duration": 90,
    "start_time": "2023-01-02T21:35:08.615Z"
   },
   {
    "duration": 2415,
    "start_time": "2023-01-02T21:35:08.706Z"
   },
   {
    "duration": 14988,
    "start_time": "2023-01-02T21:35:11.122Z"
   },
   {
    "duration": 25794,
    "start_time": "2023-01-02T21:35:26.113Z"
   },
   {
    "duration": 496,
    "start_time": "2023-01-02T21:35:51.909Z"
   },
   {
    "duration": 2829,
    "start_time": "2023-01-02T21:43:51.682Z"
   },
   {
    "duration": 71,
    "start_time": "2023-01-02T21:43:54.514Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T21:43:54.587Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-02T21:43:54.598Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-02T21:43:54.622Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-02T21:43:54.642Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T21:43:54.666Z"
   },
   {
    "duration": 104,
    "start_time": "2023-01-02T21:43:54.697Z"
   },
   {
    "duration": 2260,
    "start_time": "2023-01-02T21:43:54.804Z"
   },
   {
    "duration": 2724,
    "start_time": "2023-01-02T21:45:50.742Z"
   },
   {
    "duration": 68,
    "start_time": "2023-01-02T21:45:53.469Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T21:45:53.539Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-02T21:45:53.548Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-02T21:45:53.570Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-02T21:45:53.598Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T21:45:53.615Z"
   },
   {
    "duration": 85,
    "start_time": "2023-01-02T21:45:53.623Z"
   },
   {
    "duration": 2287,
    "start_time": "2023-01-02T21:45:53.710Z"
   },
   {
    "duration": 2923,
    "start_time": "2023-01-02T21:59:16.676Z"
   },
   {
    "duration": 71,
    "start_time": "2023-01-02T21:59:19.601Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T21:59:19.678Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-02T21:59:19.688Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-02T21:59:19.719Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-02T21:59:19.740Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T21:59:19.765Z"
   },
   {
    "duration": 32,
    "start_time": "2023-01-02T21:59:19.775Z"
   },
   {
    "duration": 2284,
    "start_time": "2023-01-02T21:59:19.809Z"
   },
   {
    "duration": 142685,
    "start_time": "2023-01-02T21:59:22.095Z"
   },
   {
    "duration": 28,
    "start_time": "2023-01-02T22:01:44.781Z"
   },
   {
    "duration": 89,
    "start_time": "2023-01-02T22:01:44.810Z"
   },
   {
    "duration": 3695,
    "start_time": "2023-01-02T22:01:44.901Z"
   },
   {
    "duration": 246145,
    "start_time": "2023-01-02T22:01:48.598Z"
   },
   {
    "duration": 154,
    "start_time": "2023-01-02T22:05:54.745Z"
   },
   {
    "duration": 2328,
    "start_time": "2023-01-02T22:05:54.901Z"
   },
   {
    "duration": 135788,
    "start_time": "2023-01-02T22:05:57.231Z"
   },
   {
    "duration": 495,
    "start_time": "2023-01-02T22:08:13.020Z"
   },
   {
    "duration": 2782,
    "start_time": "2023-01-02T22:24:20.747Z"
   },
   {
    "duration": 73,
    "start_time": "2023-01-02T22:24:23.531Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T22:24:23.606Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-02T22:24:23.617Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-02T22:24:23.636Z"
   },
   {
    "duration": 38,
    "start_time": "2023-01-02T22:24:23.663Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T22:24:23.703Z"
   },
   {
    "duration": 286,
    "start_time": "2023-01-02T22:24:23.711Z"
   },
   {
    "duration": 2626,
    "start_time": "2023-01-02T22:24:24.003Z"
   },
   {
    "duration": 16944,
    "start_time": "2023-01-03T06:53:13.792Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.739Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.740Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.741Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.742Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.743Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.744Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.745Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.746Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.747Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.748Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.749Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.750Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.751Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.752Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.752Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.753Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.755Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-03T06:53:30.756Z"
   },
   {
    "duration": 48,
    "start_time": "2023-01-03T06:54:35.468Z"
   },
   {
    "duration": 1873,
    "start_time": "2023-01-03T06:57:25.784Z"
   },
   {
    "duration": 2820,
    "start_time": "2023-01-03T06:57:33.625Z"
   },
   {
    "duration": 111,
    "start_time": "2023-01-03T06:57:36.448Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-03T06:57:36.561Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-03T06:57:36.570Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-03T06:57:36.588Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-03T06:57:36.613Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-03T06:57:36.628Z"
   },
   {
    "duration": 174,
    "start_time": "2023-01-03T06:57:36.645Z"
   },
   {
    "duration": 2447,
    "start_time": "2023-01-03T06:57:36.821Z"
   },
   {
    "duration": 115195,
    "start_time": "2023-01-03T06:57:39.271Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-03T06:59:34.468Z"
   },
   {
    "duration": 216,
    "start_time": "2023-01-03T06:59:34.503Z"
   },
   {
    "duration": 4367,
    "start_time": "2023-01-03T06:59:34.721Z"
   },
   {
    "duration": 184940,
    "start_time": "2023-01-03T06:59:39.091Z"
   },
   {
    "duration": 184,
    "start_time": "2023-01-03T07:02:44.032Z"
   },
   {
    "duration": 2654,
    "start_time": "2023-01-03T07:02:44.220Z"
   },
   {
    "duration": 115511,
    "start_time": "2023-01-03T07:02:46.875Z"
   },
   {
    "duration": 181073,
    "start_time": "2023-01-03T07:04:42.387Z"
   },
   {
    "duration": 452,
    "start_time": "2023-01-03T07:07:43.461Z"
   },
   {
    "duration": 746348,
    "start_time": "2023-01-03T07:17:06.428Z"
   },
   {
    "duration": 291,
    "start_time": "2023-01-03T07:37:59.995Z"
   },
   {
    "duration": 189,
    "start_time": "2023-01-03T07:38:38.327Z"
   },
   {
    "duration": 203,
    "start_time": "2023-01-03T07:38:43.106Z"
   },
   {
    "duration": 408,
    "start_time": "2023-01-03T07:39:28.040Z"
   },
   {
    "duration": 377,
    "start_time": "2023-01-03T07:39:37.529Z"
   },
   {
    "duration": 185,
    "start_time": "2023-01-03T07:40:00.660Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-03T07:47:35.954Z"
   },
   {
    "duration": 2024,
    "start_time": "2023-01-03T07:55:22.946Z"
   },
   {
    "duration": 2109,
    "start_time": "2023-01-03T07:55:44.653Z"
   },
   {
    "duration": 2143,
    "start_time": "2023-01-03T07:56:56.558Z"
   },
   {
    "duration": 2039,
    "start_time": "2023-01-03T07:57:49.015Z"
   },
   {
    "duration": 2013,
    "start_time": "2023-01-03T07:57:59.343Z"
   },
   {
    "duration": 1952,
    "start_time": "2023-01-03T07:58:28.595Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-03T08:02:35.378Z"
   },
   {
    "duration": 194,
    "start_time": "2023-01-03T08:04:01.866Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-03T08:05:46.112Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-03T08:07:10.849Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.075px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
